{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "__author__ = 'Robert Nikutta <robert.nikutta@noirlab.edu>, Stéphanie Juneau <stephanie.juneau@noirlab.edu>, Knut Olsen <knut.olsen@noirlab.edu>, David Nidever <david.nidever@noirlab.edu>, Alice Jacques <alice.jacques@noirlab.edu>'\n",
    "__version__ = '20231029' # yyymmdd; version stamp of this notebook\n",
    "__datasets__ = ['smash_dr1', 'delve_dr2'] # datasets used in this notebook\n",
    "__keywords__ = ['science example','dwarf galaxies'], # keywords relevant to this notebook, e.g. ['science case','dwarf galaxies'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Detecting the Hydra II dwarf galaxy in SMASH DR1 - with exercises\n",
    "\n",
    "*Robert Nikutta, Stéphanie Juneau, Knut Olsen, David Nidever, Alice Jacques & Astro Data Lab Team*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of contents\n",
    "* [Goals & notebook summary](#goals)\n",
    "* [Disclaimer & Attribution](#attribution)\n",
    "* [Imports & setup](#import)\n",
    "* [Query the SMASH catalog for blue stars (expected in metal-poor dwarfs)](#query)\n",
    "* [Spatial density plot](#spatial)\n",
    "* [Detect overdensities (differential Gaussian kernels)](#kernel)\n",
    "* [Find peaks](#peaks)\n",
    "* [Visually inspect images (Simple Image Access)](#sia)\n",
    "* [CM diagrams of all stars around the peaks](#cmdiagrams)\n",
    "* [Save your results to a local file](#savefile)\n",
    "* [Exercise: Detect the Centaurus I dwarf galaxy in DELVE DR2](#exercise)\n",
    "* [Resources](#resource)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"goals\"></a>\n",
    "# Goals\n",
    "\n",
    "We will use a dwarf galaxy detection algorithm using a spatial overdensity of blue stars to re-discover the Hydra II dwarf galaxy in the SMASH DR1 dataset.  Hydra II (red circle in the map below) is one of ~60 dwarf galaxy satellites of the Milky Way.\n",
    "\n",
    "<img style=\"float: left;\" src=\"dwarfmap_nipy_spectral_r.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "**Background**\n",
    "Ultrafaint dwarf galaxies are crucial to understanding many aspects of the universe. For instance, they are dominated by dark matter; their localization in space can thus trace the large-scale structure of the dark matter distribution. Furthermore, dwarf galaxies are suspected to host intermediate-mass black holes (IMBH), which so far have eluded efforts to find them. IMBHs will naturally bridge the gap between the solar-mass black hole and super-massive blackholes that reside at the center of virtually every large galaxy.\n",
    "\n",
    "**Data retrieval**\n",
    "We will retrieve data from Field 169 of the SMASH catalog ([Nidever et al. (2017, AJ, 154, 199)](http://adsabs.harvard.edu/abs/2017AJ....154..199N)) and look for overdensities of blue objects.\n",
    "\n",
    "The required columns are RA, Dec, and the g-band and r-band magnitudes.\n",
    "\n",
    "**Detection**\n",
    "We will convolve the spatial distribution of our dataset with a pair of Gaussian kernels and subtract the results, as done in e.g. [Stanford et al. (2005, ApJ, 634, 2, L129)](http://adsabs.harvard.edu/abs/2005ApJ...634L.129S) (galaxy clusters), or [Koposov et al. (2008, ApJ, 686, 279)](http://adsabs.harvard.edu/abs/2008ApJ...686..279K) (MW satellites). This has the effect of convolving the spatial distribution with a Mexican hat filter, which is useful for detecting objects at a desired spatial scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"attribution\"></a>\n",
    "# Disclaimer & attribution\n",
    "If you use this notebook for your published science, please acknowledge the following:\n",
    "\n",
    "* Data Lab concept paper: Fitzpatrick et al., \"The NOAO Data Laboratory: a conceptual overview\", SPIE, 9149, 2014, http://dx.doi.org/10.1117/12.2057445\n",
    "\n",
    "* Data Lab disclaimer: https://datalab.noirlab.edu/disclaimers.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# std lib\n",
    "from getpass import getpass\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to suppress some astropy depracation warnings\n",
    "\n",
    "# 3rd party\n",
    "import numpy as np\n",
    "from astropy import utils, io, convolution, stats\n",
    "from astropy.visualization import make_lupton_rgb\n",
    "from photutils import find_peaks\n",
    "from pyvo.dal import sia\n",
    "import pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Data Lab\n",
    "from dl import authClient as ac, queryClient as qc\n",
    "\n",
    "# plots default setup\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " <a class=\"anchor\" id=\"query\"></a>\n",
    "# Query the SMASH DR1 database\n",
    "\n",
    "We will query the averaged photometry table from the SMASH catalog and select field #169.  We'll issue two queries, one in which we select blue (-0.4 < g-r < 0.4) star-like objects (|sharp|<0.5), and the other without those constraints, to be used for comparison. For both queries, we will avoid photometry taken only with short exposures (depthflag>1), exclude objects with fewer than 4 detections, and apply a magnitude constraint of 9 < g < 25, so as to avoid excessive contamination.\n",
    "\n",
    "## Construct the query strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "field = 169 # SMASH field number to query\n",
    "# Create a query of all sources in the Field, for comparison\n",
    "query_all =\\\n",
    "\"\"\"SELECT ra,dec,gmag,rmag\n",
    "   FROM smash_dr1.object\n",
    "   WHERE fieldid = '{:d}' AND\n",
    "         depthflag > 1 AND\n",
    "         ndetr > 3 AND ndetg > 3 AND\n",
    "         gmag BETWEEN 9 AND 25 AND random_id<10\"\"\".format(field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create the query string; SQL keyword capitalized for clarity\n",
    "#   depth > 1 = no short exposures please\n",
    "#   ndetr, ndetg > 3 = more than 3 detections in r & g bands\n",
    "#   abs(sharp) < 0.5 = avoid broad objects\n",
    "query =\\\n",
    "\"\"\"SELECT ra,dec,gmag,rmag\n",
    "   FROM smash_dr1.object\n",
    "   WHERE fieldid = '{:d}' AND\n",
    "         depthflag > 1 AND\n",
    "         ndetr > 3 AND ndetg > 3 AND\n",
    "         abs(sharp) < 0.5 AND\n",
    "         gmag BETWEEN 9 AND 25 AND\n",
    "         (gmag-rmag) BETWEEN -0.4 AND 0.4\"\"\".format(field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Submit the queries\n",
    "Running the query in synchroneous mode is very easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all = qc.query(sql=query_all,fmt='pandas') # response is by default a CSV-formatted string\n",
    "print(\"Number of objects:\", len(df_all))\n",
    "print(df_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "R = qc.query(sql=query,fmt='pandas') # response is by default a CSV-formatted string\n",
    "print(\"Number of objects:\", len(R))\n",
    "print(R.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"spatial\"></a>\n",
    "# Make a figure of the spatial distribution\n",
    "\n",
    "You might spot some overdensities already, particularly in the result with blue star-like objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(14,7), sharey=True, constrained_layout=True)\n",
    "h1 = ax1.hexbin(df_all['ra'], df_all['dec'],gridsize=200)\n",
    "ax1.set_xlabel('RA [deg]')\n",
    "ax1.set_ylabel('Dec [deg]')\n",
    "ax1.set_title('{:d} random objects'.format(len(df_all)))\n",
    "h2 = ax2.hexbin(R['ra'], R['dec'],gridsize=200)\n",
    "ax2.set_xlabel('RA [deg]')\n",
    "ax2.set_title('{:d} blue stellar objects'.format(len(R)))\n",
    "fig.colorbar(h1,label='number of objects per spatial bin');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"kernel\"></a>\n",
    "# The Dwarf Filter\n",
    "Here we define the dwarf filter as a differential convolution of a two-dimensional image using two Gaussian kernels; this has the effect of convolution with a Mexican hat filter.  The default kernel shapes look for objects on the scale of a few arcmin.  The output includes a clipped array of the convolved spatial distribution, which we will use for peak detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dwarf_filter (ra,dec,fwhm_small=2.0,fwhm_big=20):\n",
    "\n",
    "    \"\"\"Differential convolution with 2D Gaussian kernels.\n",
    "    \n",
    "       Based on Koposov et al. (2008).\n",
    "       Code by Ken Mighell and Mike Fitzpatrick.\n",
    "       Minor edits by RN.\n",
    "       \n",
    "       Parameters\n",
    "       ----------\n",
    "       ra, dec : float or array\n",
    "           RA & Dec in degrees.\n",
    "    \n",
    "       fwhm_small, fwhm_big : float\n",
    "           Full-width half maximum sizes of the small and big Gaussian kernels\n",
    "           to use in convolution, in arcminutes.\n",
    "    \"\"\"\n",
    "    \n",
    "    x, y = ra, dec\n",
    "\n",
    "    print(\"Computing differential convolution .... \",)\n",
    "\n",
    "    # Information about declination (y) [degrees]\n",
    "    ymean = (y.min() + y.max()) / 2.0\n",
    "    ydiff_arcmin = (y.max() - y.min()) * 60.0 # convert from degrees to arcmin\n",
    "\n",
    "    # Information about right ascension (x) [degrees in time]:\n",
    "    xdiff = x.max() - x.min() # angular separation [degrees (time)] \n",
    "    xmean = (x.min() + x.max()) / 2.0\n",
    "\n",
    "    # convert from degrees in time to separation in angular degrees:\n",
    "    xdiff_angular = (x.max() - x.min()) * np.cos(ymean*(np.pi/180.0))\n",
    "\n",
    "    # convert from degress to arcmin\n",
    "    xdiff_angular_arcmin = xdiff_angular * 60.0 \n",
    "\n",
    "    # Get the number of one-arcmin pixels in the X and Y directions:\n",
    "    nx = np.rint(xdiff_angular_arcmin).astype('int')\n",
    "    ny = np.rint(ydiff_arcmin).astype('int')\n",
    "\n",
    "    # Create a two-dimensional histogram of the raw counts:\n",
    "    Counts, xedges, yedges  = np.histogram2d (x, y, (nx,ny) )\n",
    "    extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "    raw_hist = Counts.T.copy()\n",
    "\n",
    "    # Make the small and big Gaussian kernels with a standard deviation\n",
    "    # of the given FWHM in arcmin^2 pixels.\n",
    "    kernel_small = convolution.Gaussian2DKernel(fwhm_small/2.35,factor=1)\n",
    "    kernel_big = convolution.Gaussian2DKernel(fwhm_big/2.35,factor=1)\n",
    "\n",
    "    # Compute the differential convolution kernels.\n",
    "    conv_big = convolution.convolve(raw_hist, kernel_big)\n",
    "    conv_small = convolution.convolve(raw_hist, kernel_small)\n",
    "    conv_delta = conv_small - conv_big\n",
    "    delta = conv_delta.copy()\n",
    "\n",
    "    # Compute statistics and the floor\n",
    "    mean = np.mean(delta, dtype='float64')\n",
    "    sigma = np.std(delta, dtype='float64')\n",
    "    sigmaRaw = np.std(raw_hist,dtype='float64')\n",
    "    floor = mean\n",
    "\n",
    "    print('dwarf_filter: mean = {:g}  sigma = {:g} sigmaRaw = {:g}'.format(mean, sigma, sigmaRaw))\n",
    "\n",
    "    clipped = delta.copy()\n",
    "    clipped[delta < floor] = floor\n",
    "\n",
    "    # Return the computed fields.\n",
    "    return raw_hist, extent, delta, clipped, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Run the dwarf filter\n",
    "We'll use the default convolution kernels of 2 and 20 arcminutes in size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "small_k, big_k = 2.0, 20.  # kernel sizes in arcminutes\n",
    "raw, extent, delta, clipped, dsigma = dwarf_filter(R['ra'],R['dec'],fwhm_small=small_k,fwhm_big=big_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Plot the convolved 2D histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,7))\n",
    "im = plt.imshow(clipped, origin='lower', aspect='auto')\n",
    "plt.xlabel('Pixel')\n",
    "plt.ylabel('Pixel')\n",
    "plt.colorbar(label='relative spatial density after convolution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Some peaks are visible, let's locate them automatically...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"peaks\"></a>\n",
    "# Identify spatial density peaks\n",
    "We'll use the `photutils` package to identify 10-sigma peaks in the clipped filtered image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find peaks\n",
    "mean, median, std = stats.sigma_clipped_stats(clipped,sigma=3.0,maxiters=5)    \n",
    "tbl = find_peaks(clipped,median+10,box_size=small_k*2)\n",
    "\n",
    "# add ra & dec positions of peaks found\n",
    "start, stop = extent[:2]\n",
    "step_size = (stop-start)/clipped.shape[1]\n",
    "xvec = np.arange(start,stop+step_size,step_size)\n",
    "start, stop = extent[2:]\n",
    "step_size = (stop-start)/clipped.shape[0]\n",
    "yvec = np.arange(start,stop+step_size,step_size)\n",
    "\n",
    "tbl['ra'] = xvec[tbl['x_peak']]\n",
    "tbl['dec'] = yvec[tbl['y_peak']]\n",
    "print(tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Show the identified density peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ecs = ['y','w'] # colors of box frames\n",
    "ax.scatter(tbl['x_peak'],tbl['y_peak'],marker='s',s=tbl['peak_value']*40,c='none',edgecolors=ecs,lw=3)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"sia\"></a>\n",
    "# Inspect the image cutouts around the peaks\n",
    "# *Simple Image Access service*\n",
    "Data Lab comes with batteries included. Image cutout and download services are built in.\n",
    "\n",
    "We'll just write two little functions:\n",
    "\n",
    "* one to download the deepest stacked images found in the given bands at a given position in the sky\n",
    "* and a function to plot several images side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up SIA\n",
    "DEF_ACCESS_URL = \"https://datalab.noirlab.edu/sia/coadd_all\"\n",
    "svc = sia.SIAService(DEF_ACCESS_URL)\n",
    "\n",
    "# to download the deepest stacked images\n",
    "def download_deepest_images(ra,dec,fov=0.1,bands=list('gri')):\n",
    "    imgTable = svc.search((ra,dec), (fov/np.cos(dec*np.pi/180), fov), verbosity=2).to_table()\n",
    "    print(\"The full image list contains {:d} entries.\".format(len(imgTable)))\n",
    "    sel0 = (imgTable['proctype'] == 'Stack') & (imgTable['prodtype'] == 'image') # basic selection\n",
    "    images = []\n",
    "    for band in bands:\n",
    "        print(\"Band {:s}: \".format(band)) #, end='')\n",
    "        sel = sel0 & (imgTable['obs_bandpass'] == band) # add 'band' to selection\n",
    "        Table = imgTable[sel] # select\n",
    "        row = Table[np.argmax(Table['exptime'].data.data.astype('float'))] # pick image with longest exposure time\n",
    "        url = row['access_url'] # get the download URL\n",
    "        print('downloading deepest stacked image...')\n",
    "        img = io.fits.getdata(utils.data.download_file(url,cache=True,show_progress=False,timeout=120)) # .decode() b/c in Python 3 url is of \"byte\" type and getdata() expects \"string\" type\n",
    "        images.append(img)\n",
    "        \n",
    "    print(\"Downloaded {:d} images.\".format(len(images)))\n",
    "    return images\n",
    "\n",
    "# to make multi panel image\n",
    "def plot_images(images,titles=list('gri'),cmap=plt.cm.gray_r):\n",
    "    fig = plt.figure(figsize=(8,10),tight_layout=True)\n",
    "    grid = plt.GridSpec(4, 3)\n",
    "    ax1 = fig.add_subplot(grid[0, 0])\n",
    "    ax2 = fig.add_subplot(grid[0, 1])\n",
    "    ax3 = fig.add_subplot(grid[0, 2])\n",
    "    ax4 = fig.add_subplot(grid[1:, 0:])\n",
    "\n",
    "    for j,ax,img in zip(np.arange(4),[ax1,ax2,ax3,ax4],images):\n",
    "        ax.imshow(img,origin='lower',interpolation='none',cmap=cmap,norm=plt.mpl.colors.PowerNorm(0.1))\n",
    "        ax.axis('off')\n",
    "        ax.set_title('{:s}'.format(titles[j]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Get images for the \"left yellow\" box\n",
    "Download the deepest stacked image cutouts (in 3 bands) around the position of the peak marked with a yellow box. Depending on network speed and system load, this can take a few seconds. Also create a 3-band false-color composite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bands = list('gri')\n",
    "idx = 0\n",
    "print(tbl['ra'][idx], tbl['dec'][idx])\n",
    "images = download_deepest_images(tbl['ra'][idx], tbl['dec'][idx], fov=0.1, bands=bands) # FOV in deg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the images, plus a false-color 3-band image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = [im-np.median(im) for im in images] # subtract median from all images for better scaling\n",
    "images += [make_lupton_rgb(*images[::-1],stretch=30)] # add a 3-color composite image\n",
    "plot_images(images,titles=bands+['3-band image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Looks like a galaxy cluster!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Now get images for the \"white center\" box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 1\n",
    "print(tbl['ra'][idx], tbl['dec'][idx])\n",
    "images = download_deepest_images(tbl['ra'][idx], tbl['dec'][idx], fov=0.1, bands=bands) # FOV in deg\n",
    "images = [im-np.median(im) for im in images] # subtract median from all images for better scaling\n",
    "images += [make_lupton_rgb(*images[::-1],stretch=30)] # add a 3-color composite image\n",
    "plot_images(images,titles=bands+['3-band image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Definitely not a galaxy cluster, but a stellar overdensity**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"cmdiagrams\"></a>\n",
    "# Query the database for stars near peaks\n",
    "Get photometry of stars within a 5 arcmin radius of each density peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def makequery(ra0,dec0,radius0=5./60.,field=169):\n",
    "    query = \"\"\"\n",
    "SELECT ra,dec,gmag,rmag FROM smash_dr1.object\n",
    "  WHERE fieldid = {:d}\n",
    "    AND depthflag > 1\n",
    "    AND abs(sharp) < 0.5\n",
    "    AND gmag BETWEEN 9 AND 25\n",
    "    AND q3c_radial_query(ra,dec,{:f},{:f},{:f})\n",
    "\"\"\".format(field,ra0,dec0,radius0)\n",
    "\n",
    "    return query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on the q3c function used above, see the [q3c GitHub page](https://github.com/segasai/q3c)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, retrieve the data for the \"left yellow\" box. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "query0 = makequery(tbl['ra'][0],tbl['dec'][0]) # center ra & dec\n",
    "R0 = qc.query(sql=query0, fmt='pandas') # using sql argument instead of the default adql\n",
    "print(R0.head()) # a Pandas method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Then compute the g-r color and add it to as a new column to the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "R0['g_r'] = R0['gmag'] - R0['rmag']\n",
    "print( R0.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Do the same for the \"white center\" box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "query1 = makequery(tbl['ra'][1],tbl['dec'][1])\n",
    "R1 = qc.query(sql=query1,fmt='pandas')\n",
    "R1['g_r'] = R1['gmag'] - R1['rmag'] # compute color\n",
    "print(R1.tail()) # another Pandas methodb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Plot color-magnitude diagrams of the peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plotpanel(axid,x,y,title='',xlim=(-1,2),ylim=(25.2,14)):\n",
    "    ax = fig.add_subplot(axid)\n",
    "    ax.scatter(x,y,marker='.',s=10, alpha=0.8)\n",
    "    ax.set_xlabel(x.name)\n",
    "    ax.set_ylabel(y.name)\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,5.5))\n",
    "plotpanel(121,R0['g_r'],R0['gmag'],'yellow box, {:d} objects'.format(len(R0)))\n",
    "plotpanel(122,R1['g_r'],R1['gmag'],'white box, {:d} objects'.format(len(R1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Compare w/ Vivas+2016\n",
    "￼￼￼<img style=\"float: left;\" src=\"Vivas2016fig9.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your photmetry table\n",
    "If you wish, you can now save your photometry table for Hydra II to a local file and take it with you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'hydra2.csv'\n",
    "R0.to_csv(outfile,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"exercise\"></a>\n",
    "# Exercise: Detect the Centaurus I dwarf galaxy in DELVE DR2\n",
    "Now we will run through the same process to re-discover the Centaurus I dwarf galaxy in the DELVE DR2 dataset ([Mau et al. 2020](https://ui.adsabs.harvard.edu/abs/2020ApJ...890..136M/abstract))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fill in the blanks in the query\n",
    "Query the `delve_dr2.objects` table for the following columns:\n",
    "- ra\n",
    "- dec\n",
    "- mag_auto_g\n",
    "- mag_auto_r\n",
    "\n",
    "And with the following constraints:\n",
    "- Within a radius of 0.5 arcmins of RA=189.58 and Dec=-40.89\n",
    "- Limit the g-band value between 14 and 23\n",
    "- Only blue objects (-0.4 < g-r < 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT ra, dec, mag_auto_g, mag_auto_r\n",
    "FROM __\n",
    "WHERE q3c_radial_query(ra, dec, __, __, 0.5)\n",
    "      AND __ BETWEEN __ AND __\n",
    "      AND (__ - __) BETWEEN __ AND __\"\"\"\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Submit the query\n",
    "Run the query in synchroneous mode and make the output format `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = __\n",
    "print(\"Number of objects:\", len(df))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Make a figure of the spatial distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,6))\n",
    "plt.hexbin(__, __, gridsize=200)\n",
    "plt.xlabel('RA [deg]')\n",
    "plt.ylabel('Dec [deg]')\n",
    "plt.colorbar(label='number of objects per spatial bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run the dwarf filter using the same dwarf filter function from before\n",
    "We'll use the default convolution kernels of 2 and 20 arcminutes in size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "small_k, big_k = __, __  # kernel sizes in arcminutes\n",
    "raw, extent, delta, clipped, dsigma = dwarf_filter(__, __, fwhm_small=__, fwhm_big=__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Plot the convolved 2D histogram\n",
    "One dense peak will be visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,6))\n",
    "im = plt.imshow(__)\n",
    "plt.xlabel('pixel')\n",
    "plt.ylabel('pixel')\n",
    "plt.colorbar(label='relative spatial density after convolution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Identify peaks\n",
    "We'll use the `photutils` package to identify 3-sigma peaks in the clipped filtered image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find peaks\n",
    "mean, median, std = stats.sigma_clipped_stats(__, sigma=3.0, maxiters=5)\n",
    "print(f'Mean = {mean}, Median = {median}, Std = {std}')\n",
    "tbl = find_peaks(__, median+3, box_size=small_k*2)\n",
    "\n",
    "# add ra & dec positions of peaks found\n",
    "start, stop = extent[:2]\n",
    "step_size = (stop-start)/clipped.shape[1]\n",
    "xvec = np.arange(start,stop+step_size,step_size)\n",
    "start, stop = extent[2:]\n",
    "step_size = (stop-start)/clipped.shape[0]\n",
    "yvec = np.arange(start,stop+step_size,step_size)\n",
    "\n",
    "tbl['ra'] = xvec[tbl['x_peak']]\n",
    "tbl['dec'] = yvec[tbl['y_peak']]\n",
    "print(tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Show the identified density peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ecs = ['w'] # color of box frame\n",
    "ax.scatter(__, __, marker='s', s=tbl['peak_value']*40,\n",
    "           c='none', edgecolors=ecs, lw=3)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Additional ideas for advanced users\n",
    "\n",
    "* Find overdensities elsewhere (everywhere!)\n",
    "\n",
    "* Optimize kernel sizes automatically, computation, proper wavelets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Resources\n",
    "\n",
    "Koposov et al. (2008, ApJ, 686, 279) \"The Luminosity Function of the Milky Way Satellites\": http://adsabs.harvard.edu/abs/2008ApJ...686..279K\n",
    "\n",
    "Martin et al. (2015, ApJ, 804, 5) \"Hydra II: A Faint and Compact Milky Way Dwarf Galaxy Found in the Survey of the Magellanic Stellar History\": http://adsabs.harvard.edu/abs/2015ApJ...804L...5M\n",
    "\n",
    "Mau et al. (2020, ApJ, 890, 2 ) \"Two Ultra-faint Milky Way Stellar Systems Discovered in Early Data from the DECam Local Volume Exploration Survey\": https://ui.adsabs.harvard.edu/abs/2020ApJ...890..136M\n",
    "\n",
    "Nidever et al. (2017) \"SMASH - Survey of the MAgellanic Stellar History\": http://adsabs.harvard.edu/abs/2017AJ....154..199N\n",
    "\n",
    "Stanford et al. (2005, ApJ, 634, 2, L129) \"An IR-selected Galaxy Cluster at z = 1.41\": http://adsabs.harvard.edu/abs/2005ApJ...634L.129S"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "DL Py3.9 (Default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
